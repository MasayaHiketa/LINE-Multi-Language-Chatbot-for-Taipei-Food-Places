# #line_bot.py


# import os
# import re
# from fastapi import FastAPI, Request, HTTPException
# from linebot import LineBotApi, WebhookParser
# from linebot.models import FlexSendMessage
# from linebot.exceptions import InvalidSignatureError
# from ramen_qa import answer_ramen
# # â† è¿½åŠ ï¼ˆæœ€ä¸Šéƒ¨ï¼‰
# from geo_utils import extract_location_from_text

# app = FastAPI()

# LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET")
# LINE_CHANNEL_TOKEN  = os.getenv("LINE_CHANNEL_TOKEN")
# GOOGLE_API_KEY      = os.getenv("GOOGLE_API_KEY")
# if not LINE_CHANNEL_SECRET or not LINE_CHANNEL_TOKEN:
#     raise RuntimeError("LINE_CHANNEL_SECRET ã¨ LINE_CHANNEL_TOKEN ã‚’è¨­å®šã—ã¦ãã ã•ã„")

# line_bot_api = LineBotApi(LINE_CHANNEL_TOKEN)
# parser = WebhookParser(LINE_CHANNEL_SECRET)


# def parse_response_to_dict(text: str) -> dict:
#     raw = {}
#     for line in text.splitlines():
#         line = line.strip()
#         if "ï¼š" in line:
#             key, val = line.split("ï¼š", 1)
#         elif ":" in line:
#             key, val = line.split(":", 1)
#         else:
#             continue
#         raw[key.strip()] = val.strip()

#     # ãƒ©ãƒ™ãƒ«æ­£è¦åŒ–ï¼ˆè‹±â†’ä¸­ï¼‰
#     normalize = {
#         "åº—å": "åº—å",
#         "Name": "åº—å",

#         "è©•åƒ¹": "è©•åƒ¹",
#         "Rating": "è©•åƒ¹",

#         "åœ°å€": "åœ°å€",
#         "Address": "åœ°å€",

#         "æ¨è–¦": "æ¨è–¦",
#         "Recommendation": "æ¨è–¦",
#         "Recommendations": "æ¨è–¦",

#         "ç‰¹è‰²": "ç‰¹è‰²",
#         "Features": "ç‰¹è‰²",

#         "ç‡Ÿæ¥­æ™‚é–“": "ç‡Ÿæ¥­æ™‚é–“",
#         "Opening Hours": "ç‡Ÿæ¥­æ™‚é–“",
#         "Hours of Operation": "ç‡Ÿæ¥­æ™‚é–“",

#         "Link": "Link",
#         "é€£çµ": "Link",
#         "URL": "Link",
#     }

#     data = {}
#     for k, v in raw.items():
#         data[normalize.get(k, k)] = v
#     return data

# # âŠ è¿½åŠ ï¼šURLæ­£è¦åŒ–ãƒ˜ãƒ«ãƒ‘ãƒ¼
# def _normalize_link(raw: str) -> str:
#     if not raw:
#         return ""
#     s = raw.strip()

#     # Markdown [text](https://...) â†’ https://...
#     m = re.search(r"\((https?://[^\s)]+)\)", s)
#     if m:
#         s = m.group(1)

#     # ã‚‚ã—ç”Ÿã® https://... ãŒå…¥ã£ã¦ã„ã‚Œã°ãã‚Œã‚’æ‹¾ã†
#     if not s.startswith("http"):
#         m2 = re.search(r"(https?://[^\s]+)", s)
#         if m2:
#             s = m2.group(1)
#         else:
#             return ""  # http/https ä»¥å¤–ã¯æ¨ã¦ã‚‹ï¼ˆLINEã§å¼¾ã‹ã‚Œã‚‹ï¼‰

#     # ç©ºç™½ã¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
#     s = s.replace(" ", "%20")

#     # æœ«å°¾ã®å…¨è§’/å¥èª­ç‚¹/ã‚«ãƒƒã‚³é–‰ã˜ãªã©ã‚’è½ã¨ã™
#     s = s.rstrip("ã€‚ï¼‰ã€)]ï¼‰")

#     return s



# def build_ramen_flex(data: dict, photo_url: str = "") -> dict:
#     body_contents = []

#     if photo_url:
#         body_contents.append({
#             "type": "image",
#             "url": photo_url,
#             "size": "full",
#             "aspectMode": "cover",
#             "aspectRatio": "20:13",
#             "gravity": "top"
#         })

#     name = data.get("åº—å")
#     if name:
#         body_contents.append({
#             "type": "text",
#             "text": name,
#             "weight": "bold",
#             "size": "xl",
#             "wrap": True
#         })

#     rating_val = data.get("è©•åƒ¹")
#     if rating_val:
#         body_contents.append({
#             "type": "text",
#             "text": f"è©•åƒ¹ï¼š{rating_val}",
#             "size": "sm",
#             "color": "#ff9900",
#             "margin": "xs",
#             "wrap": True
#         })

#     for key, prefix in [
#         ("åœ°å€", ""),
#         ("æ·é‹ç«™", "æ·é‹ç«™ï¼š"),
#         ("æ¨è–¦", "æ¨è–¦ï¼š"),
#         ("ç‰¹è‰²", "ç‰¹è‰²ï¼š"),
#         ("ç‡Ÿæ¥­æ™‚é–“", "ç‡Ÿæ¥­æ™‚é–“ï¼š"),
#     ]:
#         val = data.get(key)
#         if not val:
#             continue
#         if key == "ç‡Ÿæ¥­æ™‚é–“":
#             times = re.findall(r'\d{1,2}:\d{2}\s*[â€“-]\s*\d{1,2}:\d{2}', val)
#             val = "; ".join(times) if times else val

#         block = {
#             "type": "text",
#             "text": f"{prefix}{val}" if prefix else val,
#             "size": "sm",
#             "color": "#666666",
#             "margin": "xs",
#             "wrap": True
#         }
#         if key == "ç‰¹è‰²":
#             block["maxLines"] = 3
#         body_contents.append(block)

#     # âœ… ãƒ•ãƒƒã‚¿ãƒ¼ã®åœ°å›³URLã‚’æ­£è¦åŒ–
#     link_raw = data.get("Link", "")
#     link = _normalize_link(link_raw)

#     flex = {
#         "type": "bubble",
#         "body": {"type": "box", "layout": "vertical", "contents": body_contents},
#     }

#     if link:
#         flex["footer"] = {
#             "type": "box",
#             "layout": "vertical",
#             "spacing": "sm",
#             "contents": [{
#                 "type": "button",
#                 "style": "link",
#                 "height": "sm",
#                 "action": {"type": "uri", "label": "æŸ¥çœ‹åœ°åœ–", "uri": link}
#             }],
#             "flex": 0
#         }

#     return flex




# from linebot.models import CarouselContainer

# @app.post("/callback")
# async def callback(request: Request):
#     signature = request.headers.get("X-Line-Signature", "")
#     body = await request.body()

#     try:
#         events = parser.parse(body.decode(), signature)
#     except InvalidSignatureError:
#         raise HTTPException(status_code=400, detail="Invalid signature")

#     for event in events:
#         if event.type == "message" and event.message.type == "text":
#             user_text = event.message.text

#             # âœ¨ åœ°åã‹ã‚‰åº§æ¨™æŠ½å‡ºã—ã¦ metadata_filter ã«å¤‰æ›
#             lat, lng = extract_location_from_text(user_text, GOOGLE_API_KEY)
#             metadata_filter = None
#             if lat is not None and lng is not None:
#                 metadata_filter = {"location": {"lat": lat, "lng": lng}}

#             # â›³ åœ°åã‚’åæ˜ ã—ãŸçŠ¶æ…‹ã§æ¤œç´¢
#             raw_replies = answer_ramen(user_text, metadata_filters=metadata_filter)

#             bubbles = []
#             for result in raw_replies[:10]:
#                 data = parse_response_to_dict(result["text"])
#                 photo_url = result.get("photo_url", "")
#                 bubble = build_ramen_flex(data, photo_url=photo_url)
#                 bubbles.append(bubble)

#             if not bubbles:
#                 return "OK"

#             flex_carousel = {
#                 "type": "carousel",
#                 "contents": bubbles
#             }

#             message = FlexSendMessage(
#                 alt_text="é¤å»³è³‡è¨Šï¼ˆè¤‡æ•°ï¼‰",
#                 contents=flex_carousel
#             )
#             line_bot_api.reply_message(event.reply_token, message)

#     return "OK"
#line_bot.py

import os
import re
import urllib.parse
from fastapi import FastAPI, Request, HTTPException
from linebot import LineBotApi, WebhookParser
from linebot.models import FlexSendMessage
from linebot.exceptions import InvalidSignatureError
from ramen_qa import answer_ramen
from geo_utils import extract_location_from_text  # åœ°åâ†’åº§æ¨™

app = FastAPI()

LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET")
LINE_CHANNEL_TOKEN  = os.getenv("LINE_CHANNEL_TOKEN")
GOOGLE_API_KEY      = os.getenv("GOOGLE_API_KEY")
if not LINE_CHANNEL_SECRET or not LINE_CHANNEL_TOKEN:
    raise RuntimeError("LINE_CHANNEL_SECRET ã¨ LINE_CHANNEL_TOKEN ã‚’è¨­å®šã—ã¦ãã ã•ã„")

line_bot_api = LineBotApi(LINE_CHANNEL_TOKEN)
parser = WebhookParser(LINE_CHANNEL_SECRET)

# ============ 1) å¤šè¨€èªâ†’æ¨™æº–ã‚­ãƒ¼ï¼ˆç¹ä¸­ï¼‰ã¸æ­£è¦åŒ– ============

# å…¥åŠ›ã®å¯èƒ½æ€§ãŒã‚ã‚‹ãƒ©ãƒ™ãƒ«: ZH/EN/JA ã‚’ç¶²ç¾…
_NORMALIZE_LABEL = {
    # åº—å / Name
    "åº—å": "åº—å",
    "Name": "åº—å",
    "åç¨±": "åº—å",
    "åå‰": "åº—å",

    # è©•åƒ¹ / Rating / è©•ä¾¡
    "è©•åƒ¹": "è©•åƒ¹",
    "Rating": "è©•åƒ¹",
    "è©•åˆ¤": "è©•åƒ¹",
    "è©•ä¾¡": "è©•åƒ¹",

    # åœ°å€ / Address / ä½æ‰€
    "åœ°å€": "åœ°å€",
    "Address": "åœ°å€",
    "ä½æ‰€": "åœ°å€",

    # æ¨è–¦ / Recommendations / ãŠã™ã™ã‚
    "æ¨è–¦": "æ¨è–¦",
    "Recommendation": "æ¨è–¦",
    "Recommendations": "æ¨è–¦",
    "Recommended": "æ¨è–¦",
    "ãŠã™ã™ã‚": "æ¨è–¦",

    # ç‰¹è‰² / Features / ç‰¹å¾´
    "ç‰¹è‰²": "ç‰¹è‰²",
    "Features": "ç‰¹è‰²",
    "Feature": "ç‰¹è‰²",
    "ç‰¹å¾´": "ç‰¹è‰²",

    # ç‡Ÿæ¥­æ™‚é–“ / Opening Hours / å–¶æ¥­æ™‚é–“
    "ç‡Ÿæ¥­æ™‚é–“": "ç‡Ÿæ¥­æ™‚é–“",
    "Opening Hours": "ç‡Ÿæ¥­æ™‚é–“",
    "Hours of Operation": "ç‡Ÿæ¥­æ™‚é–“",
    "Business Hours": "ç‡Ÿæ¥­æ™‚é–“",
    "å–¶æ¥­æ™‚é–“": "ç‡Ÿæ¥­æ™‚é–“",

    # Link / é€£çµ / ãƒªãƒ³ã‚¯ / URL
    "Link": "Link",
    "é€£çµ": "Link",
    "URL": "Link",
    "ãƒªãƒ³ã‚¯": "Link",
}

# å—ã‘å–ã‚Šãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€Œã‚­ãƒ¼ï¼šå€¤ã€ã‚’æŠœãï¼ˆå…¨è§’/åŠè§’ã‚³ãƒ­ãƒ³ä¸¡å¯¾å¿œï¼‰
def parse_response_to_dict(text: str) -> dict:
    raw = {}
    # è¨±å®¹ã™ã‚‹ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ï¼ˆå…¨è§’ã‚³ãƒ­ãƒ³ã€åŠè§’ã‚³ãƒ­ãƒ³ã€å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’å«ã‚€ï¼‰
    for line in text.splitlines():
        s = line.strip()
        if not s:
            continue

        # ã¾ãš "ï¼š" å…¨è§’ã§åˆ†å‰²
        if "ï¼š" in s:
            key, val = s.split("ï¼š", 1)
        elif ":" in s:
            key, val = s.split(":", 1)
        else:
            # ã€ŒRating 4.5ã€ã¿ãŸã„ãªã‚±ãƒ¼ã‚¹ã¯ç„¡è¦–
            continue

        key = key.strip()
        val = val.strip()

        # æœ«å°¾ã®è£…é£¾ï¼ˆã€‚ï¼‰ã€)]ï¼‰ ãªã©ï¼‰ã‚’è½ã¨ã™
        val = val.rstrip("ã€‚ï¼‰ã€)]ï¼‰")

        # æ­£è¦åŒ–
        std_key = _NORMALIZE_LABEL.get(key, key)
        # æ—¢ã«åŒã˜ã‚­ãƒ¼ãŒå…¥ã£ã¦ã„ã‚‹å ´åˆã¯ã€Œæœ€åˆã«æ¥ãŸã‚‚ã®ã‚’å„ªå…ˆã€
        raw.setdefault(std_key, val)

    return raw

# ============ 2) URL æ­£è¦åŒ– & ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆ ============

def _normalize_link(raw: str) -> str:
    """Linkæ¬„ã‹ã‚‰httpsç³»URLã‚’æŠ½å‡ºãƒ»æ•´å½¢ã€‚ãªã‘ã‚Œã°ç©ºæ–‡å­—ã€‚"""
    if not raw:
        return ""
    s = raw.strip()

    # Markdown [text](https://...) â†’ https://...
    m = re.search(r"\((https?://[^\s)]+)\)", s)
    if m:
        s = m.group(1)

    # ã€Œhttp(s)://...ã€ãŒç´ ã§å…¥ã£ã¦ã„ã‚‹å ´åˆã‚’æ‹¾ã†
    if not s.startswith("http"):
        m2 = re.search(r"(https?://[^\s]+)", s)
        if m2:
            s = m2.group(1)
        else:
            return ""

    # ç©ºç™½ã¯%20
    s = s.replace(" ", "%20")
    # æœ«å°¾ã®å…¨è§’/å¥èª­ç‚¹/ã‚«ãƒƒã‚³é–‰ã˜ãªã©ã‚’è½ã¨ã™
    s = s.rstrip("ã€‚ï¼‰ã€)]ï¼‰")
    return s

def _build_maps_query_url(name: str = "", address: str = "") -> str:
    """LinkãŒç„¡ã„ã¨ãç”¨ã« Google Maps æ¤œç´¢URLã‚’ç”Ÿæˆã€‚"""
    q_parts = [p for p in [name, address] if p]
    if not q_parts:
        return ""
    q = urllib.parse.quote(" ".join(q_parts))
    return f"https://www.google.com/maps/search/?api=1&query={q}"

# ============ 3) Flex Message ç”Ÿæˆ ============

def _extract_hours_compact(val: str) -> str:
    """
    å–¶æ¥­æ™‚é–“ã®æ–‡å­—åˆ—ã‹ã‚‰æ™‚é–“ãƒ¬ãƒ³ã‚¸ï¼ˆ12:00 â€“ 21:00 ãªã©ï¼‰ã‚’æŠœã„ã¦åœ§ç¸®è¡¨ç¤ºã€‚
    'â€“' 'â€”' '-' 'ã€œ' ã„ãšã‚Œã‚‚è¨±å®¹ã€‚
    """
    # ãƒ€ãƒƒã‚·ãƒ¥é¡ã‚’çµ±ä¸€
    val_norm = re.sub(r"[â€”â€“âˆ’~ã€œ-]", "-", val)
    # 12:00 - 21:00 ã‚’åé›†ï¼ˆè¤‡æ•°å¯ï¼‰
    times = re.findall(r"\d{1,2}:\d{2}\s*-\s*\d{1,2}:\d{2}", val_norm)
    return "; ".join(times) if times else val

def build_ramen_flex(data: dict, photo_url: str = "") -> dict:
    body_contents = []

    if photo_url:
        body_contents.append({
            "type": "image",
            "url": photo_url,
            "size": "full",
            "aspectMode": "cover",
            "aspectRatio": "20:13",
            "gravity": "top"
        })

    name = data.get("åº—å")
    if name:
        body_contents.append({
            "type": "text",
            "text": name,
            "weight": "bold",
            "size": "xl",
            "wrap": True
        })

    rating_val = data.get("è©•åƒ¹")
    if rating_val:
        body_contents.append({
            "type": "text",
            "text": f"è©•åƒ¹ï¼š{rating_val}",
            "size": "sm",
            "color": "#ff9900",
            "margin": "xs",
            "wrap": True
        })

    # æœ¬æ–‡åˆ—ï¼ˆé †åºå›ºå®šï¼‰
    for key, prefix in [
        ("åœ°å€", ""),
        ("æ¨è–¦", "æ¨è–¦ï¼š"),
        ("ç‰¹è‰²", "ç‰¹è‰²ï¼š"),
        ("ç‡Ÿæ¥­æ™‚é–“", "ç‡Ÿæ¥­æ™‚é–“ï¼š"),
    ]:
        val = data.get(key)
        if not val:
            continue

        if key == "ç‡Ÿæ¥­æ™‚é–“":
            val = _extract_hours_compact(val)

        block = {
            "type": "text",
            "text": f"{prefix}{val}" if prefix else val,
            "size": "sm",
            "color": "#666666",
            "margin": "xs",
            "wrap": True
        }
        if key == "ç‰¹è‰²":
            block["maxLines"] = 3  # é•·ã™ãã‚‹å¯¾ç­–
        body_contents.append(block)

    # ãƒ•ãƒƒã‚¿ãƒ¼ã®åœ°å›³URLï¼ˆLinkå„ªå…ˆâ†’ç„¡ã‘ã‚Œã°åº—å/ä½æ‰€ã‹ã‚‰ç”Ÿæˆï¼‰
    link = _normalize_link(data.get("Link", ""))
    if not link:
        link = _build_maps_query_url(name=name or "", address=data.get("åœ°å€", ""))

    flex = {
        "type": "bubble",
        "body": {"type": "box", "layout": "vertical", "contents": body_contents},
    }

    if link:
        flex["footer"] = {
            "type": "box",
            "layout": "vertical",
            "spacing": "sm",
            "contents": [{
                "type": "button",
                "style": "link",
                "height": "sm",
                "action": {"type": "uri", "label": "æŸ¥çœ‹åœ°åœ–", "uri": link}
            }],
            "flex": 0
        }

    return flex

# ============ 4) Webhook ============

@app.post("/callback")
async def callback(request: Request):
    signature = request.headers.get("X-Line-Signature", "")
    body = await request.body()

    try:
        events = parser.parse(body.decode(), signature)
    except InvalidSignatureError:
        raise HTTPException(status_code=400, detail="Invalid signature")

    for event in events:
        if event.type == "message" and event.message.type == "text":
            user_text = event.message.text

            # åœ°åâ†’åº§æ¨™â†’metadata_filter
            lat, lng = extract_location_from_text(user_text, GOOGLE_API_KEY)
            metadata_filter = None
            if lat is not None and lng is not None:
                metadata_filter = {"location": {"lat": lat, "lng": lng}}

            # RAGæ¤œç´¢
            raw_replies = answer_ramen(user_text, metadata_filters=metadata_filter)

            bubbles = []
            for result in raw_replies[:10]:
                data = parse_response_to_dict(result.get("text", ""))
                if not data:  # ä½•ã‚‚å–ã‚Œãªã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—
                    continue
                photo_url = result.get("photo_url", "")
                bubble = build_ramen_flex(data, photo_url=photo_url)
                bubbles.append(bubble)

            if not bubbles:
                return "OK"

            flex_carousel = {"type": "carousel", "contents": bubbles}
            message = FlexSendMessage(alt_text="é¤å»³è³‡è¨Š", contents=flex_carousel)
            line_bot_api.reply_message(event.reply_token, message)

    return "OK"
line_bot.py
-*- coding: utf-8 -*-
import time
import os
import re
import urllib.parse
from fastapi import FastAPI, Request, HTTPException
from linebot import LineBotApi, WebhookParser
from linebot.models import FlexSendMessage
from linebot.exceptions import InvalidSignatureError
from ramen_qa import answer_ramen
from geo_utils import extract_location_from_text  # åœ°åâ†’åº§æ¨™
import logging, sys

LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
logger = logging.getLogger("line_app")
if not logger.handlers:
    h = logging.StreamHandler(sys.stdout)
    h.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(name)s: %(message)s"))
    logger.addHandler(h)
logger.setLevel(LOG_LEVEL)
from urllib.parse import urlsplit, parse_qs  # â† parse_qs å¿…é ˆ


app = FastAPI()
PUBLIC_BASE_URL = os.getenv("PUBLIC_BASE_URL", "").rstrip("/")

LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET")
LINE_CHANNEL_TOKEN  = os.getenv("LINE_CHANNEL_TOKEN")
PUBLIC_BASE_URL = os.getenv("PUBLIC_BASE_URL", "").rstrip("/")
GOOGLE_API_KEY  = os.getenv("GOOGLE_MAPS_API_KEY") or os.getenv("GOOGLE_API_KEY")

logger.info(f"ğŸŒ PUBLIC_BASE_URL = {PUBLIC_BASE_URL or '(empty)'}")
logger.info(f"ğŸ”‘ GOOGLE_API_KEY set = {bool(GOOGLE_API_KEY)}")

if not LINE_CHANNEL_SECRET or not LINE_CHANNEL_TOKEN:
    raise RuntimeError("LINE_CHANNEL_SECRET ã¨ LINE_CHANNEL_TOKEN ã‚’è¨­å®šã—ã¦ãã ã•ã„")

line_bot_api = LineBotApi(LINE_CHANNEL_TOKEN)
parser = WebhookParser(LINE_CHANNEL_SECRET)

import requests
from fastapi import Response

import os
import logging

logger = logging.getLogger("line_app")

def _extract_ref_from_url(url: str) -> str:
    if not url:
        return ""
    try:
        qs = parse_qs(urlsplit(url).query)
        return qs.get("photo_reference", [""])[0]
    except Exception:
        return ""
    
@app.get("/photo/{ref:path}")
def photo_proxy(ref: str):
    try:
        logger.info(f"ğŸ“¸ /photo hit ref(raw)='{ref}'")
        orig_ref = ref

        # 1) .jpg/.png ã‚’å‰¥ãŒã™
        for ext in (".jpg", ".jpeg", ".png", ".webp"):
            if ref.lower().endswith(ext):
                ref = ref[: -len(ext)]
                break

        # 2) URL ä¸¸ã”ã¨æ¥ãŸå ´åˆã¯ photo_reference æŠœã
        if ref.startswith("http"):
            qs = parse_qs(urlsplit(ref).query)
            ref = qs.get("photo_reference", [None])[0] or ref

        # 3) å½¢ãŒæ€ªã—ã‘ã‚Œã° 204
        if not ref or len(ref) < 10:
            logger.warning(f"/photo invalid ref: orig='{orig_ref}' parsed='{ref}'")
            return Response(status_code=204)

        # 4) Google Places Photo å©ãï¼ˆãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆè¿½å¾“ï¼‰
        google_key = os.getenv("GOOGLE_API_KEY")
        if not google_key:
            logger.error("GOOGLE_API_KEY is not set")
            return Response(status_code=204)

        google_url = (
            "https://maps.googleapis.com/maps/api/place/photo"
            f"?maxwidth=800&photo_reference={ref}&key={google_key}"
        )
        logger.debug(f"/photo fetch -> {google_url.replace(google_key, '***')}")

        r = requests.get(google_url, timeout=15, allow_redirects=True)
        ctype = r.headers.get("Content-Type", "")
        logger.debug(f"/photo resp status={r.status_code} ctype='{ctype}' bytes={len(r.content) if r.ok else 0}")

        if r.status_code != 200 or not ctype.startswith("image/"):
            # ã‚¨ãƒ©ãƒ¼ãƒœãƒ‡ã‚£ã¯çŸ­ã
            body_head = r.text[:120] if hasattr(r, "text") else ""
            logger.warning(f"/photo non-image or error: status={r.status_code} ctype='{ctype}' body_head={body_head!r}")
            return Response(status_code=204)

        # 5) æˆåŠŸ
        return Response(
            content=r.content,
            media_type=ctype or "image/jpeg",
            headers={"Cache-Control": "public, max-age=86400"},
        )

    except Exception as e:
        logger.exception(f"/photo fatal error: {e}")
        return Response(status_code=204)
@app.get("/photo/{ref:path}")
def photo_proxy(ref: str):
    orig_ref = ref
    logger.debug(f"ğŸ“¸ /photo hit: orig='{orig_ref}'")
    ...
    logger.debug(f"/photo fetch -> {safe_url}")
    ...
    logger.debug(f"/photo resp status={r.status_code} ctype='{ctype}' bytes={len(r.content) if r.ok else 0}")
    # .jpg/.png æ‹¡å¼µå­ã‚’è¨±å®¹
    for ext in (".jpg", ".jpeg", ".png", ".webp"):
        if ref.lower().endswith(ext):
            ref = ref[: -len(ext)]
            break

    # URL ä¸¸ã”ã¨ã®å ´åˆã¯ photo_reference ã‚’æŠ½å‡º
    if ref.startswith("http"):
        qs = parse_qs(urlsplit(ref).query)
        ref = qs.get("photo_reference", [None])[0] or ref

    if not ref or len(ref) < 10:
        logger.warning(f"/photo invalid ref: orig='{orig_ref}' parsed='{ref}'")
        return Response(status_code=204)

    google_url = (
        "https://maps.googleapis.com/maps/api/place/photo"
        f"?maxwidth=800&photo_reference={ref}&key={GOOGLE_API_KEY}"
    )
    safe_url = google_url.replace(GOOGLE_API_KEY or "", "***")
    logger.debug(f"/photo fetch -> {safe_url}")

    try:
        r = requests.get(google_url, timeout=12, allow_redirects=True)
    except Exception as e:
        logger.exception(f"/photo request error: {e}")
        return Response(status_code=204)

    ctype = r.headers.get("Content-Type", "")
    logger.debug(f"/photo resp status={r.status_code} ctype='{ctype}' bytes={len(r.content) if r.ok else 0}")

    # Places Photo ãŒå¤±æ•—ã™ã‚‹ã¨ 4xx + JSON/HTMLï¼ˆé image/*ï¼‰ã«ãªã‚ŠãŒã¡
    if r.status_code != 200 or not ctype.startswith("image/"):
        logger.warning(f"/photo non-image or error: status={r.status_code} ctype='{ctype}' body_head={r.text[:120]!r}")
        return Response(status_code=204)

    return Response(
        content=r.content,
        media_type=ctype or "image/jpeg",
        headers={"Cache-Control": "public, max-age=86400"},
    )
    logger.warning(f"/photo non-image or error: status={r.status_code} ctype='{ctype}' body_head={r.text[:120]!r}")

@app.get("/photo/{ref:path}")
def photo_proxy(ref: str):
    # 1) æœ«å°¾ã®æ‹¡å¼µå­ã‚’å‰¥ãŒã™ï¼ˆ/photo/XXXX.jpg ã‚’è¨±å®¹ï¼‰
    for ext in (".jpg", ".jpeg", ".png", ".webp"):
        if ref.lower().endswith(ext):
            ref = ref[: -len(ext)]
            break

    # 2) ref ãŒé•·ã„URLã®å¯èƒ½æ€§ï¼ˆæ—§å®Ÿè£…ã‹ã‚‰ã®æµç”¨ãªã©ï¼‰
    if ref.startswith("http"):
        qs = parse_qs(urlsplit(ref).query)
        ref = qs.get("photo_reference", [None])[0] or ref

    # 3) photo_reference ã£ã½ããªã„å ´åˆã¯ 204
    if not ref or len(ref) < 10:
        return Response(status_code=204)

    google_url = (
        "https://maps.googleapis.com/maps/api/place/photo"
        f"?maxwidth=800&photo_reference={ref}&key={GOOGLE_API_KEY}"
    )
    r = requests.get(google_url, timeout=12, allow_redirects=True)

    # å¤±æ•— or ç”»åƒã˜ã‚ƒãªã„
    ctype = r.headers.get("Content-Type", "")
    if r.status_code != 200 or "image" not in ctype:
        return Response(status_code=204)

    return Response(
        content=r.content,
        media_type=ctype or "image/jpeg",
        headers={"Cache-Control": "public, max-age=86400"},
    )
from urllib.parse import urlsplit, parse_qs
import requests
from fastapi import Response

@app.get("/photo/{ref:path}")
def photo_proxy(ref: str):
    orig_ref = ref
    # .jpg/.pngæ‹¡å¼µå­ã‚’è¨±å®¹
    for ext in (".jpg", ".jpeg", ".png", ".webp"):
        if ref.lower().endswith(ext):
            ref = ref[: -len(ext)]
            break
    # URLä¸¸ã”ã¨æ¥ãŸå ´åˆã¯ photo_reference æŠœã
    if ref.startswith("http"):
        qs = parse_qs(urlsplit(ref).query)
        ref = qs.get("photo_reference", [None])[0] or ref

    if not ref or len(ref) < 10:
        logger.warning(f"/photo invalid ref: orig='{orig_ref}' parsed='{ref}'")
        return Response(status_code=204)

    google_url = (
        "https://maps.googleapis.com/maps/api/place/photo"
        f"?maxwidth=800&photo_reference={ref}&key={GOOGLE_API_KEY}"
    )
    safe_google_url = google_url.replace(GOOGLE_API_KEY or "", "***")
    logger.debug(f"/photo fetch: ref='{ref}' url='{safe_google_url}'")

    try:
        r = requests.get(google_url, timeout=12, allow_redirects=True)
    except Exception as e:
        logger.exception(f"/photo request error: {e}")
        return Response(status_code=204)

    ctype = r.headers.get("Content-Type", "")
    logger.debug(f"/photo resp: status={r.status_code} ctype='{ctype}' bytes={len(r.content) if r.ok else 0}")

    if r.status_code != 200 or "image" not in ctype:
        logger.warning(f"/photo non-image or error: status={r.status_code} ctype='{ctype}'")
        return Response(status_code=204)

    return Response(content=r.content, media_type=ctype or "image/jpeg",
                    headers={"Cache-Control": "public, max-age=86400"})


=========================
å¤šè¨€èªâ†’æ¨™æº–ã‚­ãƒ¼ï¼ˆç¹ä¸­ï¼‰ã¸æ­£è¦åŒ–
=========================
_NORMALIZE_LABEL = {
    # åº—å / Name
    "åº—å": "åº—å", "Name": "åº—å", "åç¨±": "åº—å", "åå‰": "åº—å",
    # è©•åƒ¹ / Rating / è©•ä¾¡
    "è©•åƒ¹": "è©•åƒ¹", "Rating": "è©•åƒ¹", "è©•åˆ¤": "è©•åƒ¹", "è©•ä¾¡": "è©•åƒ¹",
    # åœ°å€ / Address / ä½æ‰€
    "åœ°å€": "åœ°å€", "Address": "åœ°å€", "ä½æ‰€": "åœ°å€",
    # æ¨è–¦ / Recommendations / ãŠã™ã™ã‚
    "æ¨è–¦": "æ¨è–¦", "Recommendation": "æ¨è–¦", "Recommendations": "æ¨è–¦",
    "Recommended": "æ¨è–¦", "ãŠã™ã™ã‚": "æ¨è–¦",
    # ç‰¹è‰² / Features / ç‰¹å¾´
    "ç‰¹è‰²": "ç‰¹è‰²", "Features": "ç‰¹è‰²", "Feature": "ç‰¹è‰²", "ç‰¹å¾´": "ç‰¹è‰²",
    # ç‡Ÿæ¥­æ™‚é–“ / Opening Hours / å–¶æ¥­æ™‚é–“
    "ç‡Ÿæ¥­æ™‚é–“": "ç‡Ÿæ¥­æ™‚é–“", "Opening Hours": "ç‡Ÿæ¥­æ™‚é–“",
    "Hours of Operation": "ç‡Ÿæ¥­æ™‚é–“", "Business Hours": "ç‡Ÿæ¥­æ™‚é–“", "å–¶æ¥­æ™‚é–“": "ç‡Ÿæ¥­æ™‚é–“",
    # Link / é€£çµ / ãƒªãƒ³ã‚¯ / URL
    "Link": "Link", "é€£çµ": "Link", "URL": "Link", "ãƒªãƒ³ã‚¯": "Link",
}

def parse_response_to_dict(text: str) -> dict:
    raw = {}
    for line in text.splitlines():
        s = line.strip()
        if not s:
            continue

        if "ï¼š" in s:
            key, val = s.split("ï¼š", 1)
        elif ":" in s:
            key, val = s.split(":", 1)
        else:
            continue

        key = key.strip()
        val = val.strip()

        std_key = _NORMALIZE_LABEL.get(key, key)

        # â˜… æœ«å°¾ã®å¥èª­ç‚¹ã‚„ã‚«ãƒƒã‚³è½ã¨ã—ã¯ Link ã ã‘ã«é™å®š
        if std_key == "Link":
            val = val.rstrip("ã€‚ï¼ã€‚ã€ï¼‰ã€)]ã€‘ã€>")

        raw.setdefault(std_key, val)

    return raw


# =========================
# è¨€èªåˆ¤å®šï¼ˆè¶…è»½é‡ï¼‰
# =========================
def detect_locale(s: str) -> str:
    # ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠãŒã‚ã‚Œã°æ—¥æœ¬èª
    if re.search(r'[\u3040-\u30FF]', s):
        return "ja"
    # ASCIIè‹±å­—ã®æ¯”ç‡ãŒé«˜ãã€CJKã‚’å«ã¾ãªã‘ã‚Œã°è‹±èª
    ascii_letters = sum(ch.isascii() and ch.isalpha() for ch in s)
    if ascii_letters / max(1, len(s)) > 0.5 and not re.search(r'[\u4E00-\u9FFF]', s):
        return "en"
    # æ—¢å®šã¯ç¹ä½“å­—
    return "zh"

LABELS = {
    "zh": {
        "rating": "è©•åƒ¹",
        "recommend": "æ¨è–¦",
        "features": "ç‰¹è‰²",
        "hours": "ç‡Ÿæ¥­æ™‚é–“",
        "map": "æŸ¥çœ‹åœ°åœ–",
    },
    "ja": {
        "rating": "è©•ä¾¡",
        "recommend": "ãŠã™ã™ã‚",
        "features": "ç‰¹å¾´",
        "hours": "å–¶æ¥­æ™‚é–“",
        "map": "åœ°å›³ã‚’é–‹ã",
    },
    "en": {
        "rating": "Rating",
        "recommend": "Recommendations",
        "features": "Features",
        "hours": "Hours",
        "map": "Open Map",
    },
}

# =========================
# URL æ­£è¦åŒ– & ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
# =========================
import string
from urllib.parse import urlsplit, urlunsplit, quote, urlencode, parse_qsl

# --- LINEç”¨ã®å³æ ¼ãƒãƒªãƒ‡ãƒ¼ã‚¿ ---
def _is_valid_uri_for_line(url: str) -> bool:
    if not url or not isinstance(url, str):
        return False
    url = url.strip()
    # LINEã¯ http/https æ¨å¥¨ã€‚å®Ÿè³ª https ã‚’è¦æ±‚ã™ã‚‹ã‚±ãƒ¼ã‚¹ãŒå¤šã„
    if not (url.startswith("https://") or url.startswith("http://")):
        return False
    try:
        parts = urlsplit(url)
        if parts.scheme not in ("https", "http"):
            return False
        if not parts.netloc:
            return False
        # åˆ¶å¾¡æ–‡å­—ã‚„ç©ºç™½ï¼ˆå«ï¼šå…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ï¼‰ã‚’æ‹’å¦
        if any(ch.isspace() for ch in url):
            return False
        # å…¨è§’å¥èª­ç‚¹ãªã©ã¯äº‹å‰ã«é™¤å»ã—ã¦ã„ã‚‹ã¯ãšã ãŒã€æ®‹ã£ã¦ã„ãŸã‚‰NG
        bad_trailers = "ã€‚ï¼‰ã€)]ã€ã€‘ã€‘ã€‰ã€‹"
        if url[-1] in bad_trailers:
            return False
        # é•·ã•åˆ¶é™ï¼ˆå¿µã®ãŸã‚ï¼‰
        if len(url) > 1000:
            return False
    except Exception:
        return False
    return True

# --- æ­£è¦åŒ–ï¼†å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ ---
def _normalize_link(raw: str) -> str:
    """LLMã®Linkæ¬„ã‚’LINEè¨±å®¹ã®URIã¸ã€‚ãƒ€ãƒ¡ãªã‚‰ç©ºæ–‡å­—ã€‚"""
    if not raw:
        return ""
    s = raw.strip()

    # Markdown [text](URL) â†’ URL
    m = re.search(r"\((https?://[^\s)]+)\)", s)
    if m:
        s = m.group(1)

    # <https://...> ã®ã‚ˆã†ãªæ‹¬ã‚Šã‚’å‰¥ãŒã™
    if s.startswith("<") and s.endswith(">"):
        s = s[1:-1].strip()

    # ç”ŸURLã‚’æ‹¾ã†ï¼ˆæ–‡ä¸­ã®https://...ï¼‰
    if not s.startswith("http"):
        m2 = re.search(r"(https?://[^\s]+)", s)
        if m2:
            s = m2.group(1)

    # æœ«å°¾ã®å…¨è§’/å¥èª­ç‚¹/ã‚«ãƒƒã‚³é–‰ã˜ãªã©ã‚’è½ã¨ã™
    s = s.rstrip("ã€‚ï¼ã€‚ã€ï¼‰ã€)]ã€‘ã€>")

    # å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ç­‰ã®ç©ºç™½ã‚’é™¤å»
    s = re.sub(r"\s+", "", s)

    # å†ãƒ‘ãƒ¼ã‚¹ã—ã¦ path / query ã‚’é©åˆ‡ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ç›´ã™
    try:
        parts = urlsplit(s)
        if not parts.scheme or not parts.netloc:
            return ""
        safe_path   = quote(parts.path or "/", safe="/%._-~")
        # queryã‚’key-valueã«åˆ†è§£â†’å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        q_pairs = parse_qsl(parts.query, keep_blank_values=True)
        safe_query = urlencode(q_pairs, doseq=True)
        safe_frag  = quote(parts.fragment or "", safe="%-._~")
        s = urlunsplit((parts.scheme, parts.netloc, safe_path, safe_query, safe_frag))
    except Exception:
        return ""

    return s if _is_valid_uri_for_line(s) else ""

# --- Google Maps æ¤œç´¢URLç”Ÿæˆï¼ˆå®‰å…¨ç‰ˆï¼‰ ---
def _build_maps_query_url(name: str = "", address: str = "") -> str:
    q_parts = [p.strip() for p in [name, address] if p and p.strip()]
    if not q_parts:
        return ""
    # ã‚¯ã‚¨ãƒªã¯ quote_plus ã§ã¯ãªã quote ã§ç©ºç™½â†’%20ï¼ˆLINEäº’æ›æ€§é«˜ã‚ï¼‰
    q = quote(" ".join(q_parts), safe="")
    url = f"https://www.google.com/maps/search/?api=1&query={q}"
    return url if _is_valid_uri_for_line(url) else ""

# =========================
# å–¶æ¥­æ™‚é–“ã®çŸ­ç¸®æ•´å½¢
# =========================
def _extract_hours_compact(val: str) -> str:
    """
    å–¶æ¥­æ™‚é–“ã®æ–‡å­—åˆ—ã‹ã‚‰ 12:00 - 21:00 ã®ã‚ˆã†ãªæ™‚é–“ç¯„å›²ã‚’æŠ½å‡ºã—ã‚»ãƒŸã‚³ãƒ­ãƒ³é€£çµã€‚
    'â€“' 'â€”' 'âˆ’' '-' 'ã€œ' ã‚’ã™ã¹ã¦ '-' ã«æ­£è¦åŒ–ã€‚
    """
    val_norm = re.sub(r"[â€”â€“âˆ’~ã€œ-]", "-", val)
    times = re.findall(r"\d{1,2}:\d{2}\s*-\s*\d{1,2}:\d{2}", val_norm)
    return "; ".join(times) if times else val

# =========================
# Flex Message ç”Ÿæˆ
# =========================
# def build_ramen_flex(data: dict, photo_url: str = "", locale: str = "zh") -> dict:
#     labels = LABELS.get(locale, LABELS["zh"])
#     body_contents = []

#     if photo_url:
#         body_contents.append({
#             "type": "image",
#             "url": photo_url,
#             "size": "full",
#             "aspectMode": "cover",
#             "aspectRatio": "20:13",
#             "gravity": "top"
#         })

#     name = data.get("åº—å")
#     if name:
#         body_contents.append({
#             "type": "text",
#             "text": name,
#             "weight": "bold",
#             "size": "xl",
#             "wrap": True
#         })

#     rating_val = data.get("è©•åƒ¹")
#     if rating_val:
#         # æ˜Ÿï¼‹æ•°å€¤ã‚’å…¨éƒ¨é»„è‰²ã§
#         body_contents.append({
#             "type": "text",
#             "text": f"{labels['rating']}: {rating_val}",
#             "size": "sm",
#             "color": "#ffcc00",  # é»„è‰²
#             "margin": "xs",
#             "wrap": True
#         })


#     fields = [
#         ("åœ°å€", labels.get("address", "åœ°å€")),
#         ("æ¨è–¦", labels['recommend']),
#         ("ç‰¹è‰²", labels['features']),
#         ("ç‡Ÿæ¥­æ™‚é–“", labels['hours']),
#     ]
#     for key, label_title in fields:
#         val = data.get(key)
#         if not val:
#             continue
#         if key == "ç‡Ÿæ¥­æ™‚é–“":
#             val = _extract_hours_compact(val)

#         # ãƒ©ãƒ™ãƒ«ã¨å€¤ã‚’åˆ†ã‘ã¦å¼·èª¿
#         body_contents.append({
#             "type": "box",
#             "layout": "baseline",
#             "spacing": "sm",
#             "contents": [
#                 {
#                     "type": "text",
#                     "text": f"{label_title}:",  # ã‚¿ã‚¤ãƒˆãƒ«
#                     "weight": "bold",
#                     "color": "#333333",  # æ¿ƒã„ã‚°ãƒ¬ãƒ¼
#                     "size": "sm",
#                     "flex": 3,
#                     "wrap": True
#                 },
#                 {
#                     "type": "text",
#                     "text": val,  # å€¤
#                     "size": "sm",
#                     "color": "#666666",
#                     "flex": 9,
#                     "wrap": True,
#                     **({"maxLines": 3} if key == "ç‰¹è‰²" else {})
#                 }
#             ]
#         })


#     link = _normalize_link(data.get("Link", "")) or _build_maps_query_url(
#         name=name or "", address=data.get("åœ°å€", "")
#     )

#     flex = {
#         "type": "bubble",
#         "body": {"type": "box", "layout": "vertical", "contents": body_contents},
#     }

#     if link:
#         flex["footer"] = {
#             "type": "box",
#             "layout": "vertical",
#             "spacing": "sm",
#             "contents": [{
#                 "type": "button",
#                 "style": "link",
#                 "height": "sm",
#                 "action": {"type": "uri", "label": labels["map"], "uri": link}
#             }],
#             "flex": 0
#         }

#     return flex

def build_ramen_flex(data: dict, photo_url: str = "", locale: str = "zh") -> dict:
    labels = LABELS.get(locale, LABELS["zh"])

    # ===== æœ¬æ–‡ =====
    body_contents = []

    name = data.get("åº—å")
    if name:
        body_contents.append({
            "type": "text",
            "text": name,
            "weight": "bold",
            "size": "xl",
            "wrap": True
        })

    # ã€Œâ˜…4.7ã€ã®è©°ã‚è¡¨è¨˜ï¼ˆæ•°å­—ã ã‘æŠ½å‡ºã—ã¦ä»˜ä¸ï¼‰
    rating_val = data.get("è©•åƒ¹")
    if rating_val:
        import re
        m = re.search(r"\d+(?:\.\d+)?", rating_val)
        rating_num = m.group(0) if m else rating_val
        body_contents.append({
            "type": "text",
            "text": f"â˜…{rating_num}",   # â† æ˜Ÿã®å¾Œã‚ã«ã‚¹ãƒšãƒ¼ã‚¹ãªã—
            "size": "sm",
            "color": "#ffcc00",
            "margin": "xs",
            "wrap": True
        })

    # ãƒ©ãƒ™ãƒ«å¼·èª¿ï¼ˆä½æ‰€/ãŠã™ã™ã‚/ç‰¹å¾´/å–¶æ¥­æ™‚é–“ï¼‰
    fields = [
        ("åœ°å€", labels.get("address", "åœ°å€")),
        ("æ¨è–¦", labels["recommend"]),
        ("ç‰¹è‰²", labels["features"]),
        ("ç‡Ÿæ¥­æ™‚é–“", labels["hours"]),
    ]
    for key, label_title in fields:
        val = data.get(key)
        if not val:
            continue
        if key == "ç‡Ÿæ¥­æ™‚é–“":
            val = _extract_hours_compact(val)

        body_contents.append({
            "type": "box",
            "layout": "baseline",
            "spacing": "sm",
            "contents": [
                {
                    "type": "text",
                    "text": f"{label_title}:",
                    "weight": "bold",
                    "color": "#333333",
                    "size": "sm",
                    "flex": 3,
                    "wrap": True
                },
                {
                    "type": "text",
                    "text": val,
                    "size": "sm",
                    "color": "#666666",
                    "flex": 9,
                    "wrap": True,
                    **({"maxLines": 3} if key == "ç‰¹è‰²" else {})
                }
            ]
        })

    # åœ°å›³ãƒªãƒ³ã‚¯ï¼ˆLinkå„ªå…ˆâ†’ãªã‘ã‚Œã°åº—å/ä½æ‰€ã‹ã‚‰ç”Ÿæˆï¼‰
    link = _normalize_link(data.get("Link", "")) or _build_maps_query_url(
        name=name or "", address=data.get("åœ°å€", "")
    )

    # ===== Flexæœ¬ä½“ =====
    flex = {
        "type": "bubble",
        # ç”»åƒã¯ hero ã«ç½®ãï¼ˆLINE ãŒå¿…ãšå…ˆã«å–ã‚Šã«æ¥ã‚‹ï¼‰
        **({
            "hero": {
                "type": "image",
                "url": photo_url,
                "size": "full",
                "aspectMode": "cover",
                "aspectRatio": "20:13"
            }
        } if photo_url else {}),
        "body": {"type": "box", "layout": "vertical", "contents": body_contents},
    }

    if link:
        flex["footer"] = {
            "type": "box",
            "layout": "vertical",
            "spacing": "sm",
            "contents": [{
                "type": "button",
                "style": "link",
                "height": "sm",
                "action": {"type": "uri", "label": labels["map"], "uri": link}
            }],
            "flex": 0
        }

    return flex

# =========================
# Webhook
# =========================
@app.post("/callback")
async def callback(request: Request):
    logger.debug("âœ… /callback ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå±Šãã¾ã—ãŸ")

    signature = request.headers.get("X-Line-Signature", "")
    body = await request.body()

    try:
        events = parser.parse(body.decode(), signature)
    except InvalidSignatureError:
        raise HTTPException(status_code=400, detail="Invalid signature")

    for event in events:
        if event.type == "message" and event.message.type == "text":
            user_text = event.message.text
            locale = detect_locale(user_text)

            # åœ°åâ†’åº§æ¨™â†’metadata_filter
            lat, lng = extract_location_from_text(user_text, GOOGLE_API_KEY)
            metadata_filter = {"location": {"lat": lat, "lng": lng}} if (lat is not None and lng is not None) else None

            # RAGæ¤œç´¢
            try:
                raw_replies = answer_ramen(user_text, metadata_filters=metadata_filter)
            except TypeError:
                # å¤ã„ã‚·ã‚°ãƒãƒãƒ£äº’æ›ï¼ˆmetadata_filtersæœªå¯¾å¿œç‰ˆï¼‰
                raw_replies = answer_ramen(user_text)

            bubbles = []
            # for result in (raw_replies or [])[:10]:
            #     data = parse_response_to_dict(result.get("text", ""))
            #     if not data:
            #         continue
            #     photo_url = result.get("photo_url", "")
            #     bubbles.append(build_ramen_flex(data, photo_url=photo_url, locale=locale))
            # for result in (raw_replies or [])[:10]:
            #     data = parse_response_to_dict(result.get("text", ""))

            #     photo_ref = result.get("photo_ref")  # â† ã“ã‚Œã€ã¡ã‚ƒã‚“ã¨å‚ç…§å€¤ã‚’æŒã£ã¦ã¾ã™ã‹ï¼Ÿ
            #     if photo_ref:
            #         # ã‚ãªãŸã®å…¬é–‹HTTPSãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆngrokã§ã‚‚å¯ï¼‰ã€‚å¿…ãš https://
            #         photo_url = f"https://YOUR_DOMAIN/photo/{photo_ref}.jpg"
            #     else:
            #         photo_url = ""


            #     bubble = build_ramen_flex(data, photo_url=photo_url, locale=locale)
            #     bubbles.append(bubble)
            for result in (raw_replies or [])[:10]:
                data = parse_response_to_dict(result.get("text", ""))

                ref = result.get("photo_ref", "")
                logger.debug(f"ğŸ–¼ photo_ref from result: {ref}")

                if not ref:
                    ref = _extract_ref_from_url(result.get("photo_url", ""))
                    logger.debug(f"ğŸ–¼ fallback extracted ref: {ref}")

                # 3) æœ€çµ‚URLã‚’ä½œæˆï¼ˆè©²å½“ãƒ–ãƒ­ãƒƒã‚¯ã‚’ã“ã‚Œã«å·®ã—æ›¿ãˆï¼‰
                if ref:
                    if PUBLIC_BASE_URL:
                        photo_url = f"{PUBLIC_BASE_URL}/photo/{ref}.jpg?v={int(time.time())}"
                    else:
                        photo_url = str(request.url_for("photo_proxy", ref=f"{ref}.jpg"))
                        if photo_url.startswith("http://"):
                            photo_url = "https://" + photo_url[len("http://"):]
                        # æ—¢ã« ? ãŒã‚ã‚‹å ´åˆã¯ &ã€ç„¡ã‘ã‚Œã° ?
                        photo_url += f"&v={int(time.time())}" if "?" in photo_url else f"?v={int(time.time())}"
                else:
                    photo_url = ""

                logger.debug(f"ğŸ§© photo_url for Flex: {photo_url}")

                bubble = build_ramen_flex(data, photo_url=photo_url, locale=locale)
                bubbles.append(bubble)

            if not bubbles:
                # ç©ºè¿”ã—ï¼ˆä½•ã‚‚ãƒ’ãƒƒãƒˆã—ãªã„å ´åˆã‚‚ LINE ã«ã¯ 200 ã‚’è¿”ã™ï¼‰
                return "OK"

            flex_carousel = {"type": "carousel", "contents": bubbles}
            message = FlexSendMessage(alt_text="é¤å»³è³‡è¨Š", contents=flex_carousel)
            line_bot_api.reply_message(event.reply_token, message)

    return "OK"
