# -*- coding: utf-8 -*-
# line_bot.py

import time
import os
import re
import logging
import sys
import urllib.parse
from urllib.parse import (
    urlsplit, urlunsplit, parse_qs, parse_qsl, quote, urlencode
)

import requests
from fastapi import FastAPI, Request, HTTPException, Response
from linebot import LineBotApi, WebhookParser
from linebot.models import FlexSendMessage
from linebot.exceptions import InvalidSignatureError

from ramen_qa import answer_ramen
from geo_utils import extract_location_from_text  # åœ°åâ†’åº§æ¨™

# =========================
# ãƒ­ã‚®ãƒ³ã‚°
# =========================
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
logger = logging.getLogger("line_app")
if not logger.handlers:
    h = logging.StreamHandler(sys.stdout)
    h.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(name)s: %(message)s"))
    logger.addHandler(h)
logger.setLevel(LOG_LEVEL)

# =========================
# FastAPI / ç’°å¢ƒå¤‰æ•°
# =========================
app = FastAPI()

PUBLIC_BASE_URL = os.getenv("PUBLIC_BASE_URL", "").rstrip("/")
LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET")
LINE_CHANNEL_TOKEN  = os.getenv("LINE_CHANNEL_TOKEN")
# Google Maps ã¯ GOOGLE_MAPS_API_KEY å„ªå…ˆã€ç„¡ã‘ã‚Œã° GOOGLE_API_KEY
GOOGLE_API_KEY  = os.getenv("GOOGLE_MAPS_API_KEY") or os.getenv("GOOGLE_API_KEY")

logger.info(f"ğŸŒ PUBLIC_BASE_URL = {PUBLIC_BASE_URL or '(empty)'}")
logger.info(f"ğŸ”‘ GOOGLE_API_KEY set = {bool(GOOGLE_API_KEY)}")

if not LINE_CHANNEL_SECRET or not LINE_CHANNEL_TOKEN:
    raise RuntimeError("LINE_CHANNEL_SECRET ã¨ LINE_CHANNEL_TOKEN ã‚’è¨­å®šã—ã¦ãã ã•ã„")

line_bot_api = LineBotApi(LINE_CHANNEL_TOKEN)
parser = WebhookParser(LINE_CHANNEL_SECRET)

# =========================
# ãƒ©ãƒ™ãƒ«æ­£è¦åŒ–
# =========================
_NORMALIZE_LABEL = {
    # åº—å / Name
    "åº—å": "åº—å", "Name": "åº—å", "åç¨±": "åº—å", "åå‰": "åº—å",
    # è©•åƒ¹ / Rating / è©•ä¾¡
    "è©•åƒ¹": "è©•åƒ¹", "Rating": "è©•åƒ¹", "è©•åˆ¤": "è©•åƒ¹", "è©•ä¾¡": "è©•åƒ¹",
    # åœ°å€ / Address / ä½æ‰€
    "åœ°å€": "åœ°å€", "Address": "åœ°å€", "ä½æ‰€": "åœ°å€",
    # æ¨è–¦ / Recommendations / ãŠã™ã™ã‚
    "æ¨è–¦": "æ¨è–¦", "Recommendation": "æ¨è–¦", "Recommendations": "æ¨è–¦",
    "Recommended": "æ¨è–¦", "ãŠã™ã™ã‚": "æ¨è–¦",
    # ç‰¹è‰² / Features / ç‰¹å¾´
    "ç‰¹è‰²": "ç‰¹è‰²", "Features": "ç‰¹è‰²", "Feature": "ç‰¹è‰²", "ç‰¹å¾´": "ç‰¹è‰²",
    # ç‡Ÿæ¥­æ™‚é–“ / Opening Hours / å–¶æ¥­æ™‚é–“
    "ç‡Ÿæ¥­æ™‚é–“": "ç‡Ÿæ¥­æ™‚é–“", "Opening Hours": "ç‡Ÿæ¥­æ™‚é–“",
    "Hours of Operation": "ç‡Ÿæ¥­æ™‚é–“", "Business Hours": "ç‡Ÿæ¥­æ™‚é–“", "å–¶æ¥­æ™‚é–“": "ç‡Ÿæ¥­æ™‚é–“",
    # Link / é€£çµ / ãƒªãƒ³ã‚¯ / URL
    "Link": "Link", "é€£çµ": "Link", "URL": "Link", "ãƒªãƒ³ã‚¯": "Link",
}

def parse_response_to_dict(text: str) -> dict:
    """LLMã®ã€Œã‚­ãƒ¼ï¼šå€¤ã€è¡Œã‹ã‚‰è¾æ›¸ã‚’ä½œã‚‹ï¼ˆå…¨è§’/åŠè§’ã‚³ãƒ­ãƒ³å¯¾å¿œï¼‰"""
    raw = {}
    for line in text.splitlines():
        s = line.strip()
        if not s:
            continue

        if "ï¼š" in s:
            key, val = s.split("ï¼š", 1)
        elif ":" in s:
            key, val = s.split(":", 1)
        else:
            continue

        key = key.strip()
        val = val.strip()

        std_key = _NORMALIZE_LABEL.get(key, key)

        # æœ«å°¾ã®å¥èª­ç‚¹ã‚„æ‹¬å¼§ã®å‰¥ãŒã—ã¯ Link ã®ã¿å®Ÿæ–½
        if std_key == "Link":
            val = val.rstrip("ã€‚ï¼ã€‚ã€ï¼‰ã€)]ã€‘ã€>")

        raw.setdefault(std_key, val)

    return raw

# =========================
# è¨€èªåˆ¤å®š & ãƒ©ãƒ™ãƒ«
# =========================
def detect_locale(s: str) -> str:
    if re.search(r'[\u3040-\u30FF]', s):  # ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠ
        return "ja"
    ascii_letters = sum(ch.isascii() and ch.isalpha() for ch in s)
    if ascii_letters / max(1, len(s)) > 0.5 and not re.search(r'[\u4E00-\u9FFF]', s):
        return "en"
    return "zh"

LABELS = {
    "zh": {"rating": "è©•åƒ¹", "recommend": "æ¨è–¦", "features": "ç‰¹è‰²", "hours": "ç‡Ÿæ¥­æ™‚é–“", "map": "æŸ¥çœ‹åœ°åœ–"},
    "ja": {"rating": "è©•ä¾¡", "recommend": "ãŠã™ã™ã‚", "features": "ç‰¹å¾´", "hours": "å–¶æ¥­æ™‚é–“", "map": "åœ°å›³ã‚’é–‹ã"},
    "en": {"rating": "Rating", "recommend": "Recommendations", "features": "Features", "hours": "Hours", "map": "Open Map"},
}
# =========================
# =========================
def _parse_rating(rating_str: str):
    """'4.3ï¼ˆ320ä»¶ï¼‰' '4.5 (1,234 reviews)' ãªã©ã‹ã‚‰
    score(float) ã¨ count(str) ã‚’æŠœãã€‚count ã¯æ•°å­—ã ã‘ã€‚"""
    if not rating_str:
        return None, None

    # ã‚¹ã‚³ã‚¢ï¼ˆæœ€åˆã«å‡ºã‚‹æ•°å€¤ï¼‰
    score = None
    m = re.search(r'(\d+(?:\.\d+)?)', rating_str)
    if m:
        try:
            score = float(m.group(1))
        except ValueError:
            score = None

    # ä»¶æ•°ï¼ˆã‚«ãƒƒã‚³å†… or å˜ä½“ï¼‰
    count = None
    m2 = re.search(
        r'[\(ï¼ˆ]\s*([0-9][0-9,]*)\s*(?:ä»¶|å‰‡|æ¡|reviews?|ratings?|äººã®è©•ä¾¡)?\s*[\)ï¼‰]',
        rating_str,
        re.IGNORECASE
    )
    if m2:
        count = m2.group(1).replace(",", "")
    else:
        m3 = re.search(
            r'([0-9][0-9,]*)\s*(?:ä»¶|å‰‡|æ¡|reviews?|ratings?)',
            rating_str,
            re.IGNORECASE
        )
        if m3:
            count = m3.group(1).replace(",", "")

    return score, count

# =========================
# URL æ­£è¦åŒ– & ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
# =========================
def _is_valid_uri_for_line(url: str) -> bool:
    if not url or not isinstance(url, str):
        return False
    url = url.strip()
    if not (url.startswith("https://") or url.startswith("http://")):
        return False
    try:
        parts = urlsplit(url)
        if parts.scheme not in ("https", "http"):
            return False
        if not parts.netloc:
            return False
        if any(ch.isspace() for ch in url):
            return False
        if len(url) > 1000:
            return False
    except Exception:
        return False
    return True

def _normalize_link(raw: str) -> str:
    """æ–‡ä¸­ã‚„Markdownã‹ã‚‰ https URL ã‚’æŠ½å‡ºâ†’å®‰å…¨ã«æ•´å½¢ã€‚å¤±æ•—ãªã‚‰ç©ºæ–‡å­—ã€‚"""
    if not raw:
        return ""
    s = raw.strip()

    # Markdown [text](URL)
    m = re.search(r"\((https?://[^\s)]+)\)", s)
    if m:
        s = m.group(1)

    # <URL> ã®å›²ã„ã‚’å‰¥ãŒã™
    if s.startswith("<") and s.endswith(">"):
        s = s[1:-1].strip()

    # ç”ŸURLæ‹¾ã„
    if not s.startswith("http"):
        m2 = re.search(r"(https?://[^\s]+)", s)
        if m2:
            s = m2.group(1)

    # æœ«å°¾ã®å…¨è§’å¥èª­ç‚¹/æ‹¬å¼§ãªã©ã‚’è½ã¨ã™ & ç©ºç™½é™¤å»
    s = s.rstrip("ã€‚ï¼ã€‚ã€ï¼‰ã€)]ã€‘ã€>").strip()
    s = re.sub(r"\s+", "", s)

    # å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    try:
        parts = urlsplit(s)
        if not parts.scheme or not parts.netloc:
            return ""
        safe_path = quote(parts.path or "/", safe="/%._-~")
        q_pairs = parse_qsl(parts.query, keep_blank_values=True)
        safe_query = urlencode(q_pairs, doseq=True)
        safe_frag = quote(parts.fragment or "", safe="%-._~")
        s = urlunsplit((parts.scheme, parts.netloc, safe_path, safe_query, safe_frag))
    except Exception:
        return ""

    return s if _is_valid_uri_for_line(s) else ""

def _build_maps_query_url(name: str = "", address: str = "") -> str:
    q_parts = [p.strip() for p in [name, address] if p and p.strip()]
    if not q_parts:
        return ""
    q = quote(" ".join(q_parts), safe="")
    url = f"https://www.google.com/maps/search/?api=1&query={q}"
    return url if _is_valid_uri_for_line(url) else ""

# =========================
# ãƒ†ã‚­ã‚¹ãƒˆæ•´å½¢
# =========================
def _extract_hours_compact(val: str) -> str:
    """å–¶æ¥­æ™‚é–“ã® 12:00 - 21:00 ãªã©ã‚’æŠ½å‡ºã—ã¦ç°¡æ½”è¡¨è¨˜"""
    val_norm = re.sub(r"[â€”â€“âˆ’~ã€œ-]", "-", val)
    times = re.findall(r"\d{1,2}:\d{2}\s*-\s*\d{1,2}:\d{2}", val_norm)
    return "; ".join(times) if times else val

# =========================
# Photo helper
# =========================
def _extract_ref_from_url(url: str) -> str:
    """æ—¢å­˜ã®Googleç”»åƒURLã‹ã‚‰ photo_reference ã‚’æŠœã"""
    if not url:
        return ""
    try:
        qs = parse_qs(urlsplit(url).query)
        return qs.get("photo_reference", [""])[0]
    except Exception:
        return ""

# =========================
# /photo ãƒ—ãƒ­ã‚­ã‚· (Places Photo API)
# =========================
@app.get("/photo/{ref:path}")
def photo_proxy(ref: str):
    """
    Google Places Photo ã‚’å®‰å…¨ã«ãƒ—ãƒ­ã‚­ã‚·ã™ã‚‹ã€‚
    - /photo/<photo_reference>.jpg å½¢å¼ã«å¯¾å¿œï¼ˆæ‹¡å¼µå­ã¯æ¨ã¦ã‚‹ï¼‰
    - ref ã« URL ä¸¸ã”ã¨ã‚‚æ¥ãŸã‚‰ photo_reference ã‚’æŠ½å‡º
    """
    try:
        logger.info(f"ğŸ“¸ /photo hit ref(raw)='{ref}'")
        orig_ref = ref

        # æ‹¡å¼µå­å‰¥ãŒã—
        for ext in (".jpg", ".jpeg", ".png", ".webp"):
            if ref.lower().endswith(ext):
                ref = ref[: -len(ext)]
                break

        # URL ä¸¸ã”ã¨ â†’ photo_reference æŠ½å‡º
        if ref.startswith("http"):
            qs = parse_qs(urlsplit(ref).query)
            ref = qs.get("photo_reference", [None])[0] or ref

        # å½¢ãƒã‚§ãƒƒã‚¯
        if not ref or len(ref) < 10:
            logger.warning(f"/photo invalid ref: orig='{orig_ref}' parsed='{ref}'")
            return Response(status_code=204)

        if not GOOGLE_API_KEY:
            logger.error("GOOGLE_API_KEY is not set")
            return Response(status_code=204)

        google_url = (
            "https://maps.googleapis.com/maps/api/place/photo"
            f"?maxwidth=800&photo_reference={ref}&key={GOOGLE_API_KEY}"
        )
        logger.debug(f"/photo fetch -> {google_url.replace(GOOGLE_API_KEY, '***')}")

        r = requests.get(google_url, timeout=15, allow_redirects=True)
        ctype = r.headers.get("Content-Type", "")
        logger.debug(f"/photo resp status={r.status_code} ctype='{ctype}' bytes={len(r.content) if r.ok else 0}")

        if r.status_code != 200 or not ctype.startswith("image/"):
            body_head = r.text[:120] if hasattr(r, "text") else ""
            logger.warning(f"/photo non-image or error: status={r.status_code} ctype='{ctype}' body_head={body_head!r}")
            return Response(status_code=204)

        return Response(
            content=r.content,
            media_type=ctype or "image/jpeg",
            headers={"Cache-Control": "public, max-age=86400"},
        )
    except Exception as e:
        logger.exception(f"/photo fatal error: {e}")
        return Response(status_code=204)

# =========================
# Flex Message ç”Ÿæˆ
# =========================
def build_ramen_flex(data: dict, photo_url: str = "", locale: str = "zh") -> dict:
    labels = LABELS.get(locale, LABELS["zh"])

    # æœ¬æ–‡
    body_contents = []

    name = data.get("åº—å")
    if name:
        body_contents.append({
            "type": "text",
            "text": name,
            "weight": "bold",
            "size": "xl",
            "wrap": True
        })

    rating_val = data.get("è©•åƒ¹")
    if rating_val:
        score, count = _parse_rating(rating_val)
        if score is not None:
            # 5å€‹ã®â˜…/â˜†ï¼ˆå››æ¨äº”å…¥ã€0ã€œ5ã«ã‚¯ãƒªãƒƒãƒ—ï¼‰
            filled = max(0, min(5, int(round(score))))
            stars = "â˜…" * filled + "â˜†" * (5 - filled)

            body_contents.append({
                "type": "box",
                "layout": "baseline",
                "spacing": "sm",
                "contents": [
                    {
                        "type": "text",
                        "text": stars,
                        "size": "sm",
                        "color": "#ffcc00",
                        "wrap": False,
                        "flex": 0
                    },
                    {
                        "type": "text",
                        "text": f"{score:.1f}",  # â˜…ã®çœŸæ¨ªã«æ•°å€¤
                        "size": "sm",
                        "color": "#333333",
                        "margin": "sm",
                        "wrap": False,
                        "flex": 0
                    },
                    *([{
                        "type": "text",
                        "text": f"({count})",   # è©•ä¾¡æ•°ãŒå–ã‚ŒãŸã‚‰è¡¨ç¤º
                        "size": "sm",
                        "color": "#666666",
                        "margin": "sm",
                        "wrap": False,
                        "flex": 0
                    }] if count else [])
                ]
            })
        else:
            # ãƒ‘ãƒ¼ã‚¹ã§ããªã‹ã£ãŸã¨ãã®ç´ æœ´ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            body_contents.append({
                "type": "text",
                "text": rating_val,
                "size": "sm",
                "color": "#666666",
                "margin": "xs",
                "wrap": True
            })



    fields = [
        ("åœ°å€", labels.get("address", "åœ°å€")),
        ("æ¨è–¦", labels["recommend"]),
        ("ç‰¹è‰²", labels["features"]),
        ("ç‡Ÿæ¥­æ™‚é–“", labels["hours"]),
    ]
    for key, label_title in fields:
        val = data.get(key)
        if not val:
            continue
        if key == "ç‡Ÿæ¥­æ™‚é–“":
            val = _extract_hours_compact(val)

        body_contents.append({
            "type": "box",
            "layout": "baseline",
            "spacing": "sm",
            "contents": [
                {
                    "type": "text",
                    "text": f"{label_title}:",
                    "weight": "bold",
                    "color": "#333333",
                    "size": "sm",
                    "flex": 3,
                    "wrap": True
                },
                {
                    "type": "text",
                    "text": val,
                    "size": "sm",
                    "color": "#666666",
                    "flex": 9,
                    "wrap": True,
                    **({"maxLines": 3} if key == "ç‰¹è‰²" else {})
                }
            ]
        })

    link = _normalize_link(data.get("Link", "")) or _build_maps_query_url(
        name=name or "", address=data.get("åœ°å€", "")
    )

    # Flexæœ¬ä½“ï¼ˆç”»åƒã¯ hero ã«ç½®ãï¼‰
    flex = {
        "type": "bubble",
        **({
            "hero": {
                "type": "image",
                "url": photo_url,
                "size": "full",
                "aspectMode": "cover",
                "aspectRatio": "20:13"
            }
        } if photo_url else {}),
        "body": {"type": "box", "layout": "vertical", "contents": body_contents},
    }

    if link:
        flex["footer"] = {
            "type": "box",
            "layout": "vertical",
            "spacing": "sm",
            "contents": [{
                "type": "button",
                "style": "link",
                "height": "sm",
                "action": {"type": "uri", "label": labels["map"], "uri": link}
            }],
            "flex": 0
        }

    return flex

# =========================
# Webhook
# =========================
@app.post("/callback")
async def callback(request: Request):
    logger.debug("âœ… /callback ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå±Šãã¾ã—ãŸ")

    signature = request.headers.get("X-Line-Signature", "")
    body = await request.body()

    try:
        events = parser.parse(body.decode(), signature)
    except InvalidSignatureError:
        raise HTTPException(status_code=400, detail="Invalid signature")

    for event in events:
        if event.type == "message" and event.message.type == "text":
            user_text = event.message.text
            locale = detect_locale(user_text)

            # åœ°åâ†’åº§æ¨™â†’metadata_filter
            lat, lng = extract_location_from_text(user_text, GOOGLE_API_KEY)
            metadata_filter = {"location": {"lat": lat, "lng": lng}} if (lat is not None and lng is not None) else None

            # RAGæ¤œç´¢ï¼ˆå¤ã„ã‚·ã‚°ãƒãƒãƒ£äº’æ›ï¼‰
            try:
                raw_replies = answer_ramen(user_text, metadata_filters=metadata_filter)
            except TypeError:
                raw_replies = answer_ramen(user_text)

            bubbles = []
            for result in (raw_replies or [])[:10]:
                data = parse_response_to_dict(result.get("text", ""))
                if not data:
                    continue

                # photo_reference ã‚’å„ªå…ˆçš„ã«ä½¿ã†ã€‚ãªã‘ã‚Œã° photo_url ã‹ã‚‰æŠ½å‡º
                ref = result.get("photo_ref", "") or _extract_ref_from_url(result.get("photo_url", ""))
                if ref:
                    if PUBLIC_BASE_URL:
                        photo_url = f"{PUBLIC_BASE_URL}/photo/{ref}.jpg?v={int(time.time())}"
                    else:
                        # ãƒ­ãƒ¼ã‚«ãƒ«URLï¼ˆhttpâ†’https è£œæ­£ & ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚¹ã‚¿ãƒ¼ï¼‰
                        tmp = str(request.url_for("photo_proxy", ref=f"{ref}.jpg"))
                        if tmp.startswith("http://"):
                            tmp = "https://" + tmp[len("http://"):]
                        photo_url = tmp + ("&" if "?" in tmp else "?") + f"v={int(time.time())}"
                else:
                    photo_url = ""

                logger.debug(f"ğŸ§© photo_url for Flex: {photo_url}")

                bubble = build_ramen_flex(data, photo_url=photo_url, locale=locale)
                bubbles.append(bubble)

            if not bubbles:
                return "OK"

            flex_carousel = {"type": "carousel", "contents": bubbles}
            message = FlexSendMessage(alt_text="é¤å»³è³‡è¨Š", contents=flex_carousel)
            line_bot_api.reply_message(event.reply_token, message)

    return "OK"
